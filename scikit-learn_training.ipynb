{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNAuz306ZgY7OsVOPSzFaKs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Scikit-learnを用いることで以下のような統計的処理を簡単に記述することができます。\n","\n","*   Classfication(分類)\n","    *   対象がどのカテゴリーに属するかを判断する\n","    *   迷惑メール判断、画像認識\n","*   Regression(回帰)\n","    *   対象に関連する連続値の値を予想する\n","    *   薬の効果反応の予測、株価の予測\n","*   Clustering(クラスタリング)\n","    *   似た対象のグルーピングを自動化する\n","    *   顧客区分け、実験結果のグルーピング\n","*   Dimensionality reduction(次元削減)\n","    *   確率変数を削減して簡略化する\n","    *   可視化, 効率化\n","*   Model Selection(モデル選択)\n","    *   モデルを比較検討し選択する\n","    *   精度向上\n","*   Preprocessing(前処理)\n","    *   特徴抽出と正規化\n","    *   テキストのような入力データを機械学習で使えるようなデータに変換する、など \n"],"metadata":{"id":"cd5AQyraUhpk"}},{"cell_type":"markdown","source":["scikit-learnには機械学習のためのアルゴリズムモデルがたくさん用意されていて、それらのことをestimator(推定器) といいます。\n","それぞれ推定器はデータをfit(学習)することができます。例として、RandomForestClassifier にシンプルなデータを学習させてみましょう。"],"metadata":{"id":"SoTZjtTLVRVp"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","clf = RandomForestClassifier(random_state=0)\n","X = [[ 1,  2,  3],  # 2 サンプル, 特徴の数が3のデータ。\n","    [11, 12, 13]]\n","y = [0, 1]  # 教師データ。[1,2,3]のデータを0に、[11,12,13]のデータを1に対応付ける。\n","clf.fit(X, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDK63xC6VLTw","executionInfo":{"status":"ok","timestamp":1677123217139,"user_tz":-480,"elapsed":2049,"user":{"displayName":"Learning Purpose","userId":"11158023942488838844"}},"outputId":"93f44d41-e761-45af-bbdd-489c5e65b0c0"},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(random_state=0)"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["ここで、fitの引数は以下のようなものになります。\n","\n","*   X: サンプルデータ。データは行:サンプル、列:属性データの行列になる。\n","*   y: 回帰課題では実数，分類課題では整数。通常1次元の配列であり，n番目の値がXのn番目のサンプルの数値に対応する。"],"metadata":{"id":"r-Er3Os0VdGy"}},{"cell_type":"code","source":["# トレーニングデータの分類を予測する\n","clf.predict(X) # => array([0, 1])\n","\n","# 未知の値の分類予測\n","clf.predict([[4, 5, 6], [14, 15, 16]]) # => array([0, 1])\n","clf.predict([[14, 15, 16],[4, 5, 6]]) # =>array([1, 0])\n","clf.predict([[14, 15, 16],[7,8,9],[7,6,5],[4, 5, 6]]) # => array([1, 1, 0, 0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T6cqFhsqVuke","executionInfo":{"status":"ok","timestamp":1677123318578,"user_tz":-480,"elapsed":299,"user":{"displayName":"Learning Purpose","userId":"11158023942488838844"}},"outputId":"0a82ab74-131d-4d92-ec55-a703683a7e8d"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 0, 0])"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["\n","\n","\n","\n","\n","---\n","\n"],"metadata":{"id":"BM6Lj1EdWB7D"}},{"cell_type":"markdown","source":["**データ整形と前処理**"],"metadata":{"id":"yHppCDHHWHYi"}},{"cell_type":"code","source":["# StandardScalerはデータを標準化(各列の平均が0に、分散が1になるような数値の整形)する処理\n","# 平均は各データを足して要素数で割った数値\n","# 分散は各データの平均値との差を二乗し、平均をとったもの\n","from sklearn.preprocessing import StandardScaler\n","X = [[0, 15],\n","     [1, -10]]\n","ss = StandardScaler().fit(X) # フィッティングさせる。\n","ss.transform(X) # => array([[-1.,  1.],[ 1., -1.]]) # 訓練データを標準化したもの\n","Y = [[2,5],[4,-12]] # 未知データ\n","ss.transform(Y) # => array([[ 3.  ,  0.2 ],[ 7.  , -1.16]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ElcY9ZgzVViv","executionInfo":{"status":"ok","timestamp":1677123435933,"user_tz":-480,"elapsed":319,"user":{"displayName":"Learning Purpose","userId":"11158023942488838844"}},"outputId":"c9857f6f-8623-474e-da96-425443a392e4"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 3.  ,  0.2 ],\n","       [ 7.  , -1.16]])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["**パイプライン処理: 前処理と推定器を繋ぐ**"],"metadata":{"id":"Vj6PXvlDW8tC"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import make_pipeline\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# pipelineオブジェクトを作成する\n","pipe = make_pipeline(\n","    StandardScaler(), # 標準化用の前処理\n","    LogisticRegression() # ロジスティック回帰の推定器\n",")\n","\n","# アヤメのデータをロードして、トレーニングデータとテストデータに分ける\n","X, y = load_iris(return_X_y=True)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n","\n","# パイプラインを学習させる\n","pipe.fit(X_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sRaAs261WLiQ","executionInfo":{"status":"ok","timestamp":1677123659973,"user_tz":-480,"elapsed":323,"user":{"displayName":"Learning Purpose","userId":"11158023942488838844"}},"outputId":"f0ebb0c2-06e6-4cf8-b34b-1e5ebd298e5f"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('standardscaler', StandardScaler()),\n","                ('logisticregression', LogisticRegression())])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["accuracy_score(pipe.predict(X_test), y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYCSNritXCSw","executionInfo":{"status":"ok","timestamp":1677123729048,"user_tz":-480,"elapsed":6,"user":{"displayName":"Learning Purpose","userId":"11158023942488838844"}},"outputId":"b526a0bb-85d7-48c6-a500-fce53392da97"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9736842105263158"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["**モデル評価**: \n","前項のアヤメの例のように、予測の妥当性を確認する目的で学習データを訓練用データとテストデータに分けて、学習モデルの妥当性を評価する方法があり、これを交差検証(クロスバリデーション)と呼びます。\n","scikit-learnではこの交差検証を行う方法も簡単に扱えるよう用意されています。"],"metadata":{"id":"WfoXB3vEXWXE"}},{"cell_type":"code","source":["from sklearn.datasets import make_regression\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import cross_validate\n","\n","# 回帰モデル用のデータを生成する この場合はサンプル数1000、random性を排除してデータを作る\n","X, y = make_regression(n_samples=1000, random_state=0) \n","lr = LinearRegression()\n","\n","# デフォルトではデータを5分割してクロスバリデーションを行う。\n","# 詳しくはk-分割交差検証 ( https://ja.wikipedia.org/wiki/%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC#k-%E5%88%86%E5%89%B2%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC )\n","# を参照\n","result = cross_validate(lr, X, y)  \n","result['test_score']  # => array([1., 1., 1., 1., 1.]) \n","# データが簡単なので交差検証の妥当性が高い"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5GlxobmiXTLc","executionInfo":{"status":"ok","timestamp":1677123793616,"user_tz":-480,"elapsed":390,"user":{"displayName":"Learning Purpose","userId":"11158023942488838844"}},"outputId":"b3f71234-59d9-43f7-9a4f-2e5dad3f5f2c"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 1., 1., 1., 1.])"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["**自動パラメータ探索**"],"metadata":{"id":"aAEjEh86X-d2"}},{"cell_type":"markdown","source":["すべての推定器には学習時に設定するパラメータがあり、これをハイパーパラメータと呼びます。例えば、特徴量の特徴抽出方法やモデルの種類を指します。\n","推定器の応用性はいくつかのパラメータに強く依存します。例えば、RandomForestRegressor には，森の中の木の数を決める n_estimators パラメータと，各木の最大深さを決める max_depth パラメータがあります。これらのパラメータは手元のデータに依存するため、正確な値が不明な場合が非常に多いです。\n","\n","scikit-learnは最適なパラメータの組み合わせを自動的に見つけるツールを提供します。以下の例では、RandomizedSearchCV オブジェクトを用いて、ランダムフォレストのパラメータをランダムに探索します。探索が終わると，RandomizedSearchCV は最適なパラメータ・セットでフィッティングされた RandomForestRegressor として振る舞います。\n"],"metadata":{"id":"Pk8_NeDDYBaL"}},{"cell_type":"code","source":["from sklearn.datasets import fetch_california_housing\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import train_test_split\n","from scipy.stats import randint\n","\n","X, y = fetch_california_housing(return_X_y=True)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n","\n","# 探索するパラメータの範囲を指定する\n","param_distributions = {'n_estimators': randint(1, 5),\n","                       'max_depth': randint(5, 10)}\n","\n","# searchCV を作成して、データにフィッティングしましょう。\n","search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0),\n","                            n_iter=5,\n","                            param_distributions=param_distributions,\n","                            random_state=0)\n","search.fit(X_train, y_train)\n","\n","# => RandomizedSearchCV(\n","#      estimator=RandomForestRegressor(random_state=0), \n","#      n_iter=5, \n","#      aram_distributions={'max_depth': ..., 'n_estimators': ...},\n","#      random_state=0\n","# )\n","\n","search.best_params_ # => {'max_depth': 9, 'n_estimators': 4}\n","\n","# これで探索オブジェクトは norman random forest estimatorとして振る舞うようになった\n","# max_depth = 9, n_estimators=4\n","\n","# テスト用データとその教師データにたいして適用する\n","search.score(X_test, y_test) # => 0.735363411343253\n","# 比較的高い精度であることがわかる"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YDblKdB2Xi9o","executionInfo":{"status":"ok","timestamp":1677123969383,"user_tz":-480,"elapsed":6343,"user":{"displayName":"Learning Purpose","userId":"11158023942488838844"}},"outputId":"58d4068e-e074-4e7a-9e5b-edb36c9c11b0"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.735363411343253"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":[],"metadata":{"id":"PdPBR70ZYMQA"},"execution_count":null,"outputs":[]}]}